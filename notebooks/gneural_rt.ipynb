{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gneural_rt.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "iEqaAyV4iCqu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "f95d3b76-3112-4e14-a0a8-387af39558a0"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cv3XwsZoifiu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "330b94a6-807b-4c5d-ba8a-63f2d41c4b3e"
      },
      "source": [
        "!ls /content/drive/My\\ Drive/giraffe\n",
        "!cp /content/drive/My\\ Drive/giraffe/data.zip data.zip\n",
        "!unzip data.zip\n",
        "!ls\n",
        "dataset_path = '/content/drive/My Drive/giraffe/dataset_20000_128.hdf5'"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dataset_10000.hdf5  dataset_20000_128.hdf5  train\n",
            "dataset_1000.hdf5   dataset_50000.hdf5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "csQy25FJjWVf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import random_split, Dataset\n",
        "from torchvision import transforms\n",
        "from torch.autograd import Variable\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import h5py\n",
        "from PIL import Image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3kbL5ImbjbcU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RayTracingDecoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(RayTracingDecoder, self).__init__()\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(29, 64),\n",
        "            nn.ReLU(True),\n",
        "            nn.Linear(64, 128),\n",
        "            nn.ReLU(True),\n",
        "            nn.Linear(128, 256),\n",
        "            nn.ReLU(True),\n",
        "            nn.Linear(256, 256 * 256 * 3),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        x = self.decoder(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4aldCvh75WY6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class autoencoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(autoencoder, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, 3, stride=3, padding=1),  # b, 32, 10, 10\n",
        "            nn.ReLU(True),\n",
        "            nn.MaxPool2d(2, stride=2),  # b, 32, 5, 5\n",
        "            nn.Conv2d(32, 16, 3, stride=2, padding=1),  # b, 16, 3, 3\n",
        "            nn.ReLU(True),\n",
        "            nn.MaxPool2d(2, stride=1)  # b, 16, 2, 2\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.ConvTranspose2d(16, 16, 3, stride=2),  # b, 16, 5, 5\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(16, 8, 5, stride=3, padding=1),  # b, 8, 15, 15\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(8, 3, 6, stride=2, padding=1),  # b, 1, 28, 28\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = self.decoder(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Quo-RrRycTIh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AE(nn.Module):\n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__()\n",
        "        self.encoder_hidden_layer = nn.Linear(\n",
        "            in_features=kwargs[\"input_shape\"], out_features=128\n",
        "        )\n",
        "        self.encoder_output_layer = nn.Linear(\n",
        "            in_features=128, out_features=128\n",
        "        )\n",
        "        self.decoder_hidden_layer = nn.Linear(\n",
        "            in_features=128, out_features=128\n",
        "        )\n",
        "        self.decoder_output_layer = nn.Linear(\n",
        "            in_features=128, out_features=kwargs[\"input_shape\"]\n",
        "        )\n",
        "\n",
        "    def forward(self, features):\n",
        "        activation = self.encoder_hidden_layer(features)\n",
        "        activation = torch.relu(activation)\n",
        "        code = self.encoder_output_layer(activation)\n",
        "        code = torch.relu(code)\n",
        "        activation = self.decoder_hidden_layer(code)\n",
        "        activation = torch.relu(activation)\n",
        "        activation = self.decoder_output_layer(activation)\n",
        "        reconstructed = torch.relu(activation)\n",
        "        return reconstructed"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbMdPG0xjQXY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_dataset(path):\n",
        "    with h5py.File(path, \"r\") as f:\n",
        "        rgb = np.array(f[\"renders\"])\n",
        "        scenes = np.array(f[\"scenes\"]).astype(np.uint8)\n",
        "        # print(scenes[0])\n",
        "        for index, img in enumerate(rgb):\n",
        "            im = Image.fromarray(img)\n",
        "            if index == 0:\n",
        "              # im.show()\n",
        "              im.save('example.png')\n",
        "        return scenes, rgb\n",
        "\n",
        "class RayTracingDataset(Dataset):\n",
        "\n",
        "    def __init__(self, scenes, renders, transform=None):\n",
        "        '''\n",
        "        Args:\n",
        "            scenes (Numpy array)\n",
        "            renders (Numpy array)\n",
        "            transform (callable, optional)\n",
        "        '''\n",
        "        self.scenes = scenes\n",
        "        self.renders = renders\n",
        "        self.transform = transform\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.scenes)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "        \n",
        "        sample = {'scene': self.scenes[idx],\n",
        "                  'render': self.renders[idx]}\n",
        "\n",
        "        return sample\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALk5bQAxiyhA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "065ec71c-b9de-42e6-b155-282d15304b66"
      },
      "source": [
        "split_factor = 0.8\n",
        "\n",
        "# load the dataset\n",
        "scenes, rgb = load_dataset(dataset_path)\n",
        "\n",
        "img_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5], [0.5])\n",
        "])\n",
        "\n",
        "rt_dataset = RayTracingDataset(scenes=scenes, renders=rgb, transform=img_transform)\n",
        "print(\"Dataset length is {}.\".format(len(rt_dataset)))\n",
        "\n",
        "dataset_split_size = [int(len(rt_dataset) * split_factor), \n",
        "                        len(rt_dataset) - int(len(rt_dataset) * split_factor)]\n",
        "\n",
        "\n",
        "\n",
        "# split the dataset into train and test\n",
        "train_dataset, test_dataset = random_split(rt_dataset, dataset_split_size)\n",
        "\n",
        "b_size = 128\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_dataset, batch_size=b_size, shuffle=True, num_workers=4,\n",
        ")\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    test_dataset, batch_size=b_size, shuffle=False, num_workers=4\n",
        ")\n",
        "\n",
        "\n",
        "num_epochs = 200\n",
        "learning_rate = 1e-3\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# device = 'cpu'\n",
        "\n",
        "# model = RayTracingDecoder().float()\n",
        "model = AE(input_shape=49152).cuda()\n",
        "# model = autoencoder().cuda()\n",
        "# model.cuda()\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(\n",
        "    model.parameters(), lr=learning_rate, \n",
        "    weight_decay=1e-5\n",
        ")\n"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset length is 20000.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBSEE9PznI01",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 605
        },
        "outputId": "479c8a79-996c-4c37-a398-59bd833110cc"
      },
      "source": [
        "def to_img(x):\n",
        "    x = 0.5 * (x + 1)\n",
        "    x = x.clamp(0, 1)\n",
        "    x = x.view(x.size(0), 3, 128, 128)\n",
        "    return x\n",
        "\n",
        "from torchvision.utils import save_image\n",
        "\n",
        "losses = []\n",
        "for epoch in range(num_epochs):\n",
        "    for data in train_loader:\n",
        "\n",
        "        render = data['render'].float()\n",
        "        scene = data['scene'].float()\n",
        "\n",
        "        # render = render.view(-1, 3, 128, 128)\n",
        "\n",
        "        render = render.view(render.size(0), -1)\n",
        "\n",
        "        render = Variable(render).to(device)\n",
        "        scene = Variable(scene).to(device)\n",
        "\n",
        "        # print(render.shape)\n",
        "\n",
        "        output = model(render)\n",
        "\n",
        "        # print(output.shape)\n",
        "\n",
        "        loss = criterion(output, render)\n",
        "        losses.append(loss)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    \n",
        "    \n",
        "    if epoch % 10 == 0:\n",
        "        print('epoch [{}/{}], loss:{:.4f}'.format(epoch+1, num_epochs, loss.data))\n",
        "        pic = to_img(output.cpu().data)\n",
        "        save_image(pic, '/content/drive/My Drive/giraffe/train/{}.png'.format(str(epoch+1)))\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(losses)\n",
        "plt.show()\n",
        "torch.save(model.state_dict(), '/content/drive/My Drive/giraffe/train/checkpoint.pth')"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch [1/200], loss:2534.5454\n",
            "epoch [11/200], loss:2214.4509\n",
            "epoch [21/200], loss:2354.6470\n",
            "epoch [31/200], loss:2198.2615\n",
            "epoch [41/200], loss:2147.3257\n",
            "epoch [51/200], loss:2107.2578\n",
            "epoch [61/200], loss:2124.6150\n",
            "epoch [71/200], loss:2123.4207\n",
            "epoch [81/200], loss:2095.4873\n",
            "epoch [91/200], loss:2286.8208\n",
            "epoch [101/200], loss:2100.7773\n",
            "epoch [111/200], loss:2041.2566\n",
            "epoch [121/200], loss:2217.5195\n",
            "epoch [131/200], loss:2217.4302\n",
            "epoch [141/200], loss:2196.8154\n",
            "epoch [151/200], loss:2250.8345\n",
            "epoch [161/200], loss:2259.3433\n",
            "epoch [171/200], loss:2156.7275\n",
            "epoch [181/200], loss:2311.9907\n",
            "epoch [191/200], loss:2223.3152\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}